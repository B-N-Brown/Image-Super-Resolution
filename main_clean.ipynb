{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLtTqBTuRfw",
        "outputId": "9a1b715c-9d22-4334-9fc4-7493f041c240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /home/kshashank/.local/lib/python3.8/site-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /home/kshashank/.local/lib/python3.8/site-packages (from opencv-python) (1.23.4)\n",
            "Requirement already satisfied: tqdm in /home/kshashank/.local/lib/python3.8/site-packages (4.64.1)\n",
            "Requirement already satisfied: tensorflow in /home/kshashank/.local/lib/python3.8/site-packages (2.10.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (3.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: packaging in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (1.23.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/kshashank/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/kshashank/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kshashank/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kshashank/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/kshashank/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kshashank/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/kshashank/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kshashank/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kshashank/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/kshashank/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: torch in /home/kshashank/.local/lib/python3.8/site-packages (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /home/kshashank/.local/lib/python3.8/site-packages (from torch) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tqdm\n",
        "!pip install tensorflow\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6FGFFqSouRfx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm # progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Bjsesg_Lv1rx",
        "outputId": "bf72b5a9-e954-427e-e73e-fced8f6ef74a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-04 14:06:32.607616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-04 14:06:32.791671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kshashank/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-12-04 14:06:32.791709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-12-04 14:06:32.813473: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-12-04 14:06:33.387858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kshashank/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-12-04 14:06:33.387959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kshashank/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-12-04 14:06:33.387971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model\n",
        "from keras.applications import VGG19\n",
        "from keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense, PReLU, Flatten\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "48qep5BiyFNR"
      },
      "outputs": [],
      "source": [
        "#residual blocks\n",
        "def get_residual_block(a):\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides=(1, 1), padding='same', input_shape=[32, 32, 64], activation='relu')(a)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = PReLU()(x)\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides=(1, 1), padding='same', input_shape=[32, 32, 64], activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    a = Add()([x, a])\n",
        "\n",
        "    return a\n",
        "    \n",
        "    \n",
        "# create generator network\n",
        "def create_generator_network():\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # original 2 layers\n",
        "    #changed kernel to 3x3 from 9x9\n",
        "    a = Conv2D(64, kernel_size = (9, 9), strides=(1, 1), padding='same', input_shape=[32, 32, 3], activation='relu')(inputs)\n",
        "    a = PReLU()(a)\n",
        "\n",
        "    # keep track of a to sum it into the result of the residiual block methods\n",
        "    orig = a\n",
        "\n",
        "    for i in range(0, 5):\n",
        "        a = get_residual_block(a)\n",
        "\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides=(1, 1), padding='same', input_shape=[32, 32, 64], activation='relu')(a)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    a = Add()([x, orig])\n",
        "\n",
        "    for i in range(0, 2):\n",
        "        # pixel shuffle\n",
        "        a = Conv2D(256, kernel_size = (3, 3), strides=(1, 1), padding='same', input_shape=[32, 32, 64], activation='relu')(a)\n",
        "        a = UpSampling2D(2)(a)\n",
        "        a = PReLU()(a)\n",
        "\n",
        "    a = Conv2D(3, kernel_size = (9, 9), strides=(1, 1), padding='same', input_shape=[32, 32, 64], activation='relu')(a)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8iBjdzekEdBd"
      },
      "outputs": [],
      "source": [
        "# create discriminator network\n",
        "def create_discriminator_network(disc_ip):\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides=(1, 1), padding='same', input_shape=[32, 32, 3], activation='relu')(disc_ip)\n",
        "    x = LeakyReLU(alpha= 0.2)(x)\n",
        "\n",
        "    \n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, kernel_size = (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, kernel_size = (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, kernel_size = (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, kernel_size = (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, kernel_size = (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, kernel_size = (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return [disc_ip, x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#content loss \n",
        "\n",
        "def vgg_loss_function(hr_img):\n",
        "    vgg = VGG19(include_top=False, weights='imagenet', input_shape=hr_img)\n",
        "    model = Model(inputs = vgg.inputs, outputs = vgg.layers[10].output) #calling 512 \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#combined model\n",
        "\n",
        "def combined_model(generator_network, discriminator_network, \n",
        "                   vgg, hr_img, lr_img):\n",
        "\n",
        "    generative_img = generator_network(lr_img)\n",
        "\n",
        "    generative_features = vgg(generative_img)\n",
        "\n",
        "\n",
        "    discriminator_network.trainable = False\n",
        "    validity = create_discriminator_network(generative_features)\n",
        "\n",
        "    model = Model(inputs=[lr_img, hr_img], outputs=[validity, generative_features])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 178750.14it/s]\n",
            "  0%|          | 51/50000 [00:00<03:56, 211.29it/s]\n"
          ]
        }
      ],
      "source": [
        "lr_images = []\n",
        "hr_images = []\n",
        "directory = './imgs-lr'\n",
        "count = 0\n",
        "for filename in tqdm(os.listdir(directory)):\n",
        "    if count > 50:\n",
        "        continue\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    img = cv2.imread(filepath)\n",
        "    lr_images.append(img)\n",
        "    count += 1\n",
        "directory = './imgs-hr'\n",
        "count = 0\n",
        "for filename in tqdm(os.listdir(directory)):\n",
        "    if count > 50:\n",
        "        break\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    img = cv2.imread(filepath)\n",
        "    hr_images.append(img)\n",
        "    count += 1\n",
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kshashank/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#inializing parameters\n",
        "from keras.optimizers import Adam\n",
        "epochs = 100\n",
        "batch_size = 50\n",
        "steps_per_epoch = 5000 / batch_size\n",
        "optimizer = Adam(lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_images = lr_images / 255\n",
        "hr_images = hr_images / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images,\n",
        "                                                        test_size=0.20, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 32, 32, 64)   15616       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " p_re_lu_8 (PReLU)              (None, 32, 32, 64)   65536       ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 64)  256         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_9 (PReLU)              (None, 32, 32, 64)   65536       ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 32, 32, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'p_re_lu_8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 32, 32, 64)   36928       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 32, 32, 64)  256         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_10 (PReLU)             (None, 32, 32, 64)   65536       ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_10[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 32, 32, 64)  256         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_28[0][0]', \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 32, 32, 64)   36928       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 32, 32, 64)  256         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_11 (PReLU)             (None, 32, 32, 64)   65536       ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_11[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 32, 32, 64)  256         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 32, 32, 64)   36928       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 32, 32, 64)  256         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_12 (PReLU)             (None, 32, 32, 64)   65536       ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_12[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 32, 32, 64)  256         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_32[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 32, 32, 64)   36928       ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 32, 32, 64)  256         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_13 (PReLU)             (None, 32, 32, 64)   65536       ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 32, 32, 64)   36928       ['p_re_lu_13[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 32, 32, 64)  256         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_34[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 32, 32, 64)   36928       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 32, 32, 64)  256         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'p_re_lu_8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 32, 32, 256)  147712      ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 256)  0          ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " p_re_lu_14 (PReLU)             (None, 64, 64, 256)  1048576     ['up_sampling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 64, 64, 256)  590080      ['p_re_lu_14[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_44[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " p_re_lu_15 (PReLU)             (None, 128, 128, 25  4194304     ['up_sampling2d_5[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 128, 128, 3)  62211       ['p_re_lu_15[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,860,739\n",
            "Trainable params: 6,859,331\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = create_generator_network()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 64, 64, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 64, 64, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 32, 32, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 16, 16, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 16, 16, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 8, 8, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33555456  \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,249,281\n",
            "Trainable params: 38,245,569\n",
            "Non-trainable params: 3,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator_network(hr_ip)\n",
        "disc_model = Model(inputs=discriminator[0], outputs=discriminator[1])\n",
        "disc_model.compile(loss=\"binary_crossentropy\",\n",
        "                      optimizer=\"adam\", metrics=['accuracy'])\n",
        "disc_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,325,568\n",
            "Trainable params: 2,325,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "vgg = vgg_loss_function(hr_shape)\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
          ]
        }
      ],
      "source": [
        "print(hr_ip)\n",
        "print(lr_ip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "gan_model = combined_model(generator, discriminator[1], vgg, hr_ip, lr_ip)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " model_4 (Functional)           (None, 128, 128, 3)  6860739     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " model_2 (Functional)           (None, 32, 32, 256)  2325568     ['model_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 32, 32, 64)   147520      ['model_2[1][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 32, 32, 64)   0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 16, 16, 64)   36928       ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 64)  256         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 16, 16, 64)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 16, 16, 128)  73856       ['leaky_re_lu_19[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 128)  512        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 16, 16, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 128)    147584      ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 8, 8, 128)   512         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 8, 8, 128)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 256)    295168      ['leaky_re_lu_21[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 8, 8, 256)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 4, 4, 256)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 4, 4, 512)    1180160     ['leaky_re_lu_23[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_24 (LeakyReLU)     (None, 4, 4, 512)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 2, 2, 512)    2359808     ['leaky_re_lu_24[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_25 (LeakyReLU)     (None, 2, 2, 512)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 2048)         0           ['leaky_re_lu_25[0][0]']         \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1024)         2098176     ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_26 (LeakyReLU)     (None, 1024)         0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            1025        ['leaky_re_lu_26[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,124,036\n",
            "Trainable params: 13,793,348\n",
            "Non-trainable params: 2,330,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"],\n",
        "                  loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
        "gan_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for i in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/40 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [33], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#First, train the discriminator on fake and real HR images. \u001b[39;00m\n\u001b[1;32m     20\u001b[0m disc_model\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m d_loss_gen \u001b[39m=\u001b[39m disc_model\u001b[39m.\u001b[39;49mtrain_on_batch(fake_imgs, fake_label)\n\u001b[1;32m     22\u001b[0m d_loss_real \u001b[39m=\u001b[39m disc_model\u001b[39m.\u001b[39mtrain_on_batch(hr_imgs, real_label)\n\u001b[1;32m     24\u001b[0m \u001b[39m#Now, train the generator by fixing discriminator as non-trainable\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2381\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2377\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2379\u001b[0m     )\n\u001b[1;32m   2380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2381\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   2383\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "#Enumerate training over epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
        "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
        "    print(fake_label)\n",
        "    print(real_label)\n",
        "    \n",
        "    #Create empty lists to populate gen and disc losses. \n",
        "    generator_losses = []\n",
        "    discrimator_losses = []\n",
        "    \n",
        "    #Enumerate training over batches. \n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
        "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
        "        \n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
        "        \n",
        "        #First, train the discriminator on fake and real HR images. \n",
        "        disc_model.trainable = True\n",
        "        d_loss_gen = disc_model.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = disc_model.train_on_batch(hr_imgs, real_label)\n",
        "        \n",
        "        #Now, train the generator by fixing discriminator as non-trainable\n",
        "        disc_model.trainable = False\n",
        "        \n",
        "        #Average the discriminator loss, just for reporting purposes. \n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
        "        \n",
        "        #Extract VGG features, to be used towards calculating loss\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "     \n",
        "        #Train the generator via GAN. \n",
        "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "        \n",
        "        #Save losses to a list so we can average and report. \n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "        \n",
        "    #Convert the list of losses to an array to make it easy to average    \n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "    \n",
        "    #Calculate the average losses for generator and discriminator\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "    \n",
        "    #Report the progress during training. \n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
        "        #Save the generator after every n epochs (Usually 10 epochs)\n",
        "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
